{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Predict Credit Card Fraud\n",
    "\n",
    "Predict credit card fraud using the data in `fraud_data.csv`. Each row in `fraud_data.csv` corresponds to a credit card transaction. Features include confidential variables `V1` through `V28` and the `Amount` variable, which is the amount of the transaction. The target is stored in the `class` column, where a value of 1 corresponds to an instance of fraud and 0 corresponds to an instance of not fraud.\n",
    "\n",
    "This project is derived from an assignment from the online course [Applied Machine Learning in Python](https://www.coursera.org/learn/python-machine-learning). While the original assignment is organized as a series of questions and answers, I have reorganized and extended the assignment to illustrate prediction using an unbalanced data set.\n",
    "\n",
    "The data in `fraud_data.csv` is sampled from a [larger dataset obtained from Kaggle](https://www.kaggle.com/isaikumar/creditcardfraud).  The original Kaggle dataset contains an equal number of fraud and not fraud records while 'fraud_data.csv' is an unbalanced sampling with a few fraud examples and many not fraud examples. In addition, the original Kaggle dataset contains a 'Time' column, which would introduce a time-series element to the problem. The 'fraud_data.csv' data file is provided by the course."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import and inspect data from *fraud_data.csv*."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('fraud_data.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Explore the fraud data in the data frame *df*."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "21693"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1.17656255181218,\n",
       " 0.6811094859498571,\n",
       " 1.14072867493278,\n",
       " -1.1070732901366598,\n",
       " -0.314818210584509,\n",
       " -0.7132655233833951,\n",
       " 1.21906014927591,\n",
       " 0.6839181839407061,\n",
       " -1.12782007276595,\n",
       " -1.7577938917599898,\n",
       " 0.34927704693896994,\n",
       " -0.411809717463036,\n",
       " -1.1666356016218602,\n",
       " -1.15606755739674,\n",
       " -1.1900375719891598,\n",
       " -1.92745281973369,\n",
       " -1.7471742008941902,\n",
       " -2.1680014044803,\n",
       " 1.09517701629955,\n",
       " 0.0124048644403335,\n",
       " 1.24097174900597,\n",
       " -1.62395564540432,\n",
       " -0.493633979056369,\n",
       " 0.8324627381509749,\n",
       " -0.864353596974226,\n",
       " 1.01385595030302,\n",
       " -1.0325445395271,\n",
       " 0.132131572611682,\n",
       " 1.5419053698130398,\n",
       " -0.730463077360616,\n",
       " 2.29926351819561,\n",
       " 1.80018474263757,\n",
       " -0.8079246404405959,\n",
       " -0.4662322488724841,\n",
       " 2.04909443633668,\n",
       " 0.806151464766754,\n",
       " 0.972194427191706,\n",
       " 0.13756547506574898,\n",
       " -0.424757433060442,\n",
       " 2.01953764690043,\n",
       " -0.0436838787022874,\n",
       " 1.2201707983436298,\n",
       " 0.0747535224513496,\n",
       " -0.263601818479385,\n",
       " -0.3219905552906189,\n",
       " 1.21323808952138,\n",
       " 1.19057666658281,\n",
       " 1.77362261079471,\n",
       " 1.02659863249836,\n",
       " 1.24084729796184,\n",
       " -0.6014927365413721,\n",
       " 1.23823931306425,\n",
       " 2.05248123574287,\n",
       " 2.0950370153986104,\n",
       " -5.31282347126043,\n",
       " 2.2235228931126803,\n",
       " 1.17134815475683,\n",
       " 0.273141949635756,\n",
       " -0.599884134566766,\n",
       " -0.24570494364276504,\n",
       " 2.06381879873705,\n",
       " -0.2485950911774,\n",
       " 0.489602283991863,\n",
       " 1.01841181981555,\n",
       " -2.7180502624646903,\n",
       " 1.2485892554844,\n",
       " -1.30343016122972,\n",
       " -1.16961834236476,\n",
       " 0.8540874405279381,\n",
       " -0.6286567025955799,\n",
       " -0.5688415670896271,\n",
       " -0.541505212362131,\n",
       " 1.98124443052826,\n",
       " 1.07103882156489,\n",
       " 0.670075695054206,\n",
       " -0.7141720410101341,\n",
       " -1.91367543000946,\n",
       " -0.625646376169102,\n",
       " 0.27359763783651503,\n",
       " -1.67519246077785,\n",
       " 2.02199600137134,\n",
       " -1.54301612203081,\n",
       " 1.3870744542922395,\n",
       " -0.528020808751357,\n",
       " 2.09820139160177,\n",
       " -1.0419631568048,\n",
       " -0.5805761241716441,\n",
       " 1.24557277592849,\n",
       " 2.0631636490448,\n",
       " -1.71394051040566,\n",
       " -1.34075048276514,\n",
       " 2.13961909365146,\n",
       " -0.414920650777243,\n",
       " 0.8629923053409692,\n",
       " 1.19162442234776,\n",
       " -0.733255979104255,\n",
       " 1.29579535903554,\n",
       " -0.151847477649387,\n",
       " -1.20870455007487,\n",
       " 2.10315668941816,\n",
       " 1.15917305898182,\n",
       " 2.01099829738874,\n",
       " -0.213851351414913,\n",
       " 1.23853282760964,\n",
       " 1.9799469118138704,\n",
       " -0.0640674233059067,\n",
       " -0.0242666335860978,\n",
       " -3.8275490973874,\n",
       " -1.3355950612000502,\n",
       " -1.82418947185801,\n",
       " 1.25795057564073,\n",
       " 1.16366215511706,\n",
       " 1.89266748263199,\n",
       " 1.83583987822912,\n",
       " 1.2975398047230802,\n",
       " -1.15275354765925,\n",
       " -1.22320528248127,\n",
       " -2.33658229681346,\n",
       " 1.1426747862443798,\n",
       " -1.86748444863332,\n",
       " -1.3670767123216798,\n",
       " -1.66937460844919,\n",
       " -2.0244849419856,\n",
       " 1.16961744109899,\n",
       " 1.13762163742509,\n",
       " 0.9716693990455608,\n",
       " 1.5754929839769,\n",
       " -1.28845375499771,\n",
       " 1.7674071486392098,\n",
       " 0.0974790913349037,\n",
       " -6.2161962699334,\n",
       " 0.626344965359937,\n",
       " -0.9997190775867508,\n",
       " 1.2617570315406,\n",
       " 1.06167048557524,\n",
       " 1.2142988747235,\n",
       " 2.03914024920497,\n",
       " 2.0138355120901696,\n",
       " -1.05771978497694,\n",
       " -0.58130031648391,\n",
       " -0.0843782115538031,\n",
       " 1.11159158879639,\n",
       " -0.5752622083573051,\n",
       " -2.62126293838248,\n",
       " 2.06072237325581,\n",
       " -1.82513823062348,\n",
       " 1.02936755599575,\n",
       " -3.6196196622893,\n",
       " -5.07222543415359,\n",
       " 0.432554461820961,\n",
       " 1.3350119056029,\n",
       " 2.03048833537246,\n",
       " 1.50482522875323,\n",
       " 1.36373441041842,\n",
       " -1.61340623615478,\n",
       " 1.45023028323046,\n",
       " -6.5738054871864415,\n",
       " -0.148951319967965,\n",
       " -1.98850288993438,\n",
       " 1.98863953410032,\n",
       " 2.04803686239072,\n",
       " 1.22428053821118,\n",
       " 1.50762107003753,\n",
       " -0.9740515038955352,\n",
       " 1.39716926530532,\n",
       " -1.19603687019129,\n",
       " 1.02052404333931,\n",
       " -1.03113735031005,\n",
       " 0.0819401304852189,\n",
       " -0.0219830221457755,\n",
       " 1.8578815473879904,\n",
       " 0.882388758032923,\n",
       " -2.5483517345032,\n",
       " -0.240881808862076,\n",
       " -0.992833453427742,\n",
       " 1.12020865115649,\n",
       " 1.11232377714554,\n",
       " -1.25505350263991,\n",
       " -1.40819282745042,\n",
       " -0.3957081252786621,\n",
       " 1.17123629516256,\n",
       " -0.780918343582258,\n",
       " 0.908636658181293,\n",
       " 1.00406465561538,\n",
       " 1.471602109139,\n",
       " -0.4650367561434721,\n",
       " -0.0523443676292389,\n",
       " 2.22726062871333,\n",
       " -0.629968794391667,\n",
       " 2.13346580786154,\n",
       " -0.363133927036766,\n",
       " 1.93325788988342,\n",
       " -0.8589204023301479,\n",
       " 1.23881958156345,\n",
       " 0.268049627058304,\n",
       " -0.343240094271672,\n",
       " -0.686401222886554,\n",
       " 0.0482668671061233,\n",
       " 1.20113490575902,\n",
       " 2.2032701697039903,\n",
       " 0.4547697161227121,\n",
       " 0.33561971975006394,\n",
       " -1.78328460147438,\n",
       " 1.09951118276436,\n",
       " 2.02728585292786,\n",
       " 1.8087697918552,\n",
       " -1.79980457468829,\n",
       " 1.89498492337008,\n",
       " -1.41069532425012,\n",
       " 0.8986142745559059,\n",
       " -18.5951946288799,\n",
       " 0.8426919570404029,\n",
       " 1.00186164425269,\n",
       " -0.0376660831233171,\n",
       " 1.92833456719185,\n",
       " -3.15592622917162,\n",
       " 1.59890815049055,\n",
       " 2.03384089807204,\n",
       " -1.1123396569684,\n",
       " -0.16108635723282,\n",
       " -1.6299028074561497,\n",
       " -1.6333505148586598,\n",
       " 1.98561911247708,\n",
       " 0.19860881344535,\n",
       " -0.632295962095662,\n",
       " -0.15454039756212198,\n",
       " 1.32846180099548,\n",
       " -1.82453449768732,\n",
       " 2.07533455506204,\n",
       " 1.43042533619386,\n",
       " 1.13093757214405,\n",
       " -0.426123389771999,\n",
       " -1.28321645629917,\n",
       " 2.0886373000931298,\n",
       " 1.4525023732092,\n",
       " 0.6597886792068149,\n",
       " -0.6212691692052621,\n",
       " -0.297183017537734,\n",
       " 1.30976656546954,\n",
       " -0.8865296043026779,\n",
       " -1.12837151788734,\n",
       " 1.91507517108632,\n",
       " -2.68813193746517,\n",
       " -1.09255336096105,\n",
       " -1.32794706581113,\n",
       " 0.113044587420653,\n",
       " 0.9488688375959532,\n",
       " 1.27961355620624,\n",
       " 1.70407399180659,\n",
       " 1.93145734854747,\n",
       " -0.109309847849771,\n",
       " -0.5091950813116479,\n",
       " -0.35628502859932104,\n",
       " 1.31055513331528,\n",
       " 1.26179321795941,\n",
       " -22.341888886803797,\n",
       " 1.23054655975244,\n",
       " -1.25449055892103,\n",
       " -9.55191319505521,\n",
       " -0.503036867947932,\n",
       " -1.39617784540775,\n",
       " -0.247198073421454,\n",
       " 1.52707808825586,\n",
       " -2.0860568863018303,\n",
       " -0.6606411786402521,\n",
       " 0.108395344828102,\n",
       " 0.5063532353517051,\n",
       " 0.7658221018538292,\n",
       " 2.00253796026884,\n",
       " -0.928714121206647,\n",
       " -2.753713672695,\n",
       " -1.98104703274966,\n",
       " 1.00073496261342,\n",
       " -0.46187947178668,\n",
       " 1.37608802897509,\n",
       " 1.19025740679917,\n",
       " -1.09191143044984,\n",
       " -0.8011363344155559,\n",
       " -1.17308355807128,\n",
       " 0.900710634618227,\n",
       " 2.09097607129079,\n",
       " -1.7639032876216,\n",
       " 1.38666468657111,\n",
       " -0.0389656226249722,\n",
       " -2.79475044411317,\n",
       " -2.00115963381332,\n",
       " -1.61650241732572,\n",
       " -0.664579504760746,\n",
       " 0.8809970160037729,\n",
       " 1.4291995325926998,\n",
       " 1.12440399248974,\n",
       " 0.153648999002021,\n",
       " -0.13492203949258802,\n",
       " 1.64555741468492,\n",
       " 2.06968812501249,\n",
       " 0.272617869873637,\n",
       " -2.88004235163471,\n",
       " -0.606284096155304,\n",
       " -0.312015416399508,\n",
       " -16.5265065691231,\n",
       " 1.14848604134001,\n",
       " -2.1248317018355,\n",
       " -0.347588089236296,\n",
       " 1.2332660475143602,\n",
       " -0.438032641801515,\n",
       " 1.34282564850552,\n",
       " 1.9653604602807095,\n",
       " 1.4878476358863,\n",
       " 1.07276222050423,\n",
       " -4.6253182947331695,\n",
       " 1.96891313515476,\n",
       " 0.0364991137909927,\n",
       " 1.71823094449577,\n",
       " 1.0985908012911,\n",
       " -2.6830999004752902,\n",
       " -0.208160575841626,\n",
       " 0.0691984044445943,\n",
       " 1.30068897876764,\n",
       " 1.99122945776819,\n",
       " -1.61882306029198,\n",
       " -0.129772255179428,\n",
       " -0.525866600994288,\n",
       " -2.72154402013825,\n",
       " -0.38706397331903,\n",
       " 1.14421414766628,\n",
       " 1.99133422344648,\n",
       " -0.738194826446769,\n",
       " 1.9379998703784096,\n",
       " -1.17998342913274,\n",
       " -2.58038331197136,\n",
       " -0.008305546598883471,\n",
       " -0.606766643572603,\n",
       " 2.08867925337498,\n",
       " 1.9644053048443,\n",
       " -0.150276722811218,\n",
       " -0.7586738647219549,\n",
       " -0.9544606258684672,\n",
       " -0.4340725256565301,\n",
       " -0.575332747344294,\n",
       " 2.2680114173027204,\n",
       " -0.800630992680414,\n",
       " -0.41967413944540893,\n",
       " -0.6891934626777371,\n",
       " -0.7215735082253121,\n",
       " 1.18665286520133,\n",
       " -0.268159082854055,\n",
       " -0.121503190232715,\n",
       " 1.14585407826311,\n",
       " 1.89638650467176,\n",
       " -2.39869727207778,\n",
       " 1.39632364903178,\n",
       " 1.9125343005324296,\n",
       " 0.19385762663686895,\n",
       " -0.616714389792259,\n",
       " 2.16037001312435,\n",
       " 1.17375646865311,\n",
       " 0.0478269383669534,\n",
       " -3.11219479283885,\n",
       " -0.41955885498187495,\n",
       " 2.1603899250273098,\n",
       " 0.611994624027271,\n",
       " -0.642103878819367,\n",
       " -3.3793716312482,\n",
       " -0.796803695655561,\n",
       " 1.82938730891443,\n",
       " 1.42695505543196,\n",
       " 1.03801097130654,\n",
       " 0.913276204298658,\n",
       " -0.428186599353082,\n",
       " 2.01408866287888,\n",
       " -2.4225933370148702,\n",
       " -0.7665215369475451,\n",
       " -1.08024020368116,\n",
       " -0.27728292473356503,\n",
       " 2.02801599819118,\n",
       " 2.0557970063003896,\n",
       " 0.8671102881432969,\n",
       " -1.22463009846684,\n",
       " 0.00195115407973515,\n",
       " -0.280752131797808,\n",
       " -2.02594091914131,\n",
       " -0.505128695813276,\n",
       " 1.00353785968615,\n",
       " 1.9535308308198704,\n",
       " 0.3677841125367179,\n",
       " -2.4365047221493903,\n",
       " -2.08854585909841,\n",
       " -0.32251588798007,\n",
       " 0.983160597659948,\n",
       " -9.4714494686984,\n",
       " 0.213025558019283,\n",
       " 2.00149429815552,\n",
       " -0.5731537052386949,\n",
       " -3.7166306974585,\n",
       " 1.22849198529949,\n",
       " -3.1951955842149595,\n",
       " 0.9706079593255128,\n",
       " -3.47085408001544,\n",
       " -0.490494559208178,\n",
       " -0.8741304994550421,\n",
       " -0.339679041491158,\n",
       " -1.3769598111964398,\n",
       " 2.08975066103539,\n",
       " -1.33966349483871,\n",
       " 1.85505863476814,\n",
       " 1.41131507975005,\n",
       " 1.93962110091138,\n",
       " -0.457667672665933,\n",
       " 1.27761550906948,\n",
       " 1.95822735976431,\n",
       " 0.0220325649831785,\n",
       " -0.565111622967833,\n",
       " 1.80746167543938,\n",
       " 1.5613255839566895,\n",
       " 1.4240377913307398,\n",
       " 1.1622759366988,\n",
       " 2.04610731662348,\n",
       " 2.35224064673288,\n",
       " -0.495972053520565,\n",
       " -0.483359838284234,\n",
       " 2.06304604362587,\n",
       " -0.0836073213570718,\n",
       " -0.169951680983159,\n",
       " 1.16807238804054,\n",
       " -0.347400337606031,\n",
       " -1.96595679612192,\n",
       " -1.21835180830366,\n",
       " -1.27100234701619,\n",
       " 1.96916765787264,\n",
       " 1.05725283367471,\n",
       " 2.03858561911041,\n",
       " -0.458644469701829,\n",
       " -0.7524445371372929,\n",
       " -1.08344952193003,\n",
       " -0.547129401190028,\n",
       " 1.18094316453657,\n",
       " -0.9733057187310692,\n",
       " 1.1369656133531298,\n",
       " 1.88451780156427,\n",
       " -0.769999059723412,\n",
       " -0.439256689876253,\n",
       " 1.44062136629085,\n",
       " 2.27663319133211,\n",
       " 2.02633698976903,\n",
       " -0.26676497832647195,\n",
       " 1.14439620391806,\n",
       " 2.23256889877194,\n",
       " -1.16045130953944,\n",
       " -0.478502632110324,\n",
       " 1.92354177945258,\n",
       " -0.0036477597913074297,\n",
       " -0.436794708870004,\n",
       " 2.0245661251620097,\n",
       " 1.2013812997254198,\n",
       " 1.0131144998144002,\n",
       " -0.339299765587514,\n",
       " 2.05644871081364,\n",
       " 2.05210205766131,\n",
       " -0.790991937751002,\n",
       " 2.14385746319636,\n",
       " -0.0104175075904755,\n",
       " 2.0154996765395303,\n",
       " 0.939875607014415,\n",
       " -1.98019645916646,\n",
       " 2.10988271481442,\n",
       " -0.4324819726534601,\n",
       " 1.10955244307232,\n",
       " -0.509343818490148,\n",
       " 1.23977483494741,\n",
       " 1.11896859989452,\n",
       " -0.747566889023111,\n",
       " -0.572803534457162,\n",
       " 0.983199840796904,\n",
       " 1.14115913344815,\n",
       " -1.1459784665787198,\n",
       " 2.02216805298204,\n",
       " 0.915011970735192,\n",
       " 1.7879015754011005,\n",
       " 2.01111890862603,\n",
       " 0.16825546934860006,\n",
       " 1.96965870796994,\n",
       " 2.02044701244804,\n",
       " 1.05808410254283,\n",
       " -0.268179368960385,\n",
       " -1.31799315923996,\n",
       " -1.79548896226007,\n",
       " -1.73548671977525,\n",
       " 2.2475656183013,\n",
       " -2.37696423972766,\n",
       " -0.233787349150487,\n",
       " 1.21900029530168,\n",
       " -0.713499288999213,\n",
       " 1.28729755915555,\n",
       " -1.35421765716393,\n",
       " 1.24055678093169,\n",
       " -0.647438239075682,\n",
       " 1.96238760823542,\n",
       " 0.762288597199445,\n",
       " -6.15960693036327,\n",
       " 1.84468640485308,\n",
       " -2.09669150080546,\n",
       " 1.9138608860981297,\n",
       " 2.04950086417285,\n",
       " -2.7959850871993,\n",
       " 1.07982003120118,\n",
       " -2.02044150538545,\n",
       " -0.380910528477816,\n",
       " 1.14686557765077,\n",
       " 2.04652575710452,\n",
       " -4.763358128250402,\n",
       " 0.831472330877878,\n",
       " 2.0365988685743,\n",
       " 1.9067752013139,\n",
       " -0.314495602136789,\n",
       " 1.94890109205608,\n",
       " -0.5636032489767661,\n",
       " -1.05297685447669,\n",
       " -1.76631019506578,\n",
       " 2.04540503155637,\n",
       " 1.9090965165492,\n",
       " 1.9564506711546696,\n",
       " -1.27473737605323,\n",
       " 1.09531630394183,\n",
       " 1.11706705820732,\n",
       " -12.4900791894053,\n",
       " 2.03231340024793,\n",
       " 1.16675262065756,\n",
       " -1.50998543946058,\n",
       " 1.0965421127926098,\n",
       " 1.27446017632283,\n",
       " 1.1104051261147398,\n",
       " 1.96018937259938,\n",
       " -2.75718911812562,\n",
       " 1.0819253729142,\n",
       " 1.09338351932968,\n",
       " 1.92930105488326,\n",
       " -0.148992141983772,\n",
       " -1.4529355542007,\n",
       " -0.513495512648061,\n",
       " 2.09317044610652,\n",
       " -0.684386697630573,\n",
       " 1.03890748944672,\n",
       " 2.00855776793629,\n",
       " -0.549207366823735,\n",
       " 2.04246409330803,\n",
       " -1.9365044863534904,\n",
       " -1.1078368019283602,\n",
       " 1.06383947810873,\n",
       " -0.8009428445511079,\n",
       " 0.42672216589459294,\n",
       " 1.30667026281926,\n",
       " -2.39635878587326,\n",
       " 0.3378966339070309,\n",
       " 1.17835113566148,\n",
       " 1.21972591898099,\n",
       " 2.03415285137147,\n",
       " 1.15940546898225,\n",
       " 2.06904829385313,\n",
       " -0.5892667986531421,\n",
       " -0.77563715866167,\n",
       " -4.89293045914431,\n",
       " 2.29944877813381,\n",
       " 1.23249655726352,\n",
       " -3.7322764997712703,\n",
       " 1.2387668255139,\n",
       " -0.150733448571164,\n",
       " -0.19956105870521,\n",
       " 1.7477739286758798,\n",
       " -1.3015992972683,\n",
       " 2.06672972528842,\n",
       " 1.09936963808216,\n",
       " 2.03450679508695,\n",
       " -0.31263869067349104,\n",
       " -1.38966738491084,\n",
       " -0.279035811666962,\n",
       " 1.62764270764737,\n",
       " 1.1679215268234,\n",
       " 0.363686543318661,\n",
       " -2.0614501341427403,\n",
       " 1.92981439897866,\n",
       " 1.80809846489666,\n",
       " -0.517809839124754,\n",
       " 1.06536008072289,\n",
       " 1.84801081552359,\n",
       " 1.17966739018017,\n",
       " 0.0765239703697419,\n",
       " 0.7986279403281641,\n",
       " -0.111820074823017,\n",
       " -0.7147867066945709,\n",
       " -0.744552483641008,\n",
       " -0.334782643313304,\n",
       " -0.540642501329539,\n",
       " -0.0990932946064815,\n",
       " 1.81426509240226,\n",
       " -0.4691889803013521,\n",
       " 2.12928909488634,\n",
       " 1.91219448204927,\n",
       " -0.998034871982932,\n",
       " -1.1863867831165,\n",
       " 1.1428633526415102,\n",
       " 2.16688100003803,\n",
       " -2.31151436668461,\n",
       " -0.622464563547366,\n",
       " 0.7588412630510241,\n",
       " 1.20312830563619,\n",
       " -0.925528019167693,\n",
       " -0.625304431725865,\n",
       " 1.20435214215422,\n",
       " -1.19980263150022,\n",
       " 1.47814026277184,\n",
       " 0.0188663257352674,\n",
       " -1.53337492747809,\n",
       " 1.82963957855582,\n",
       " 2.15707313590445,\n",
       " -0.650355725212052,\n",
       " 0.00554441919649055,\n",
       " -2.6053370118276,\n",
       " -0.271269966546667,\n",
       " -0.9947583074553508,\n",
       " 1.22859776796413,\n",
       " -1.4755220231636998,\n",
       " 2.05498809848153,\n",
       " -1.80392761369866,\n",
       " 0.134112638272815,\n",
       " 2.08451080856314,\n",
       " -0.561892531075945,\n",
       " -2.57642370592856,\n",
       " 2.03071523655557,\n",
       " 2.01125778222487,\n",
       " -1.43768180333837,\n",
       " -0.8456770645964441,\n",
       " 1.88257027824026,\n",
       " -1.07961076764633,\n",
       " -2.09655284131349,\n",
       " -1.66389435635445,\n",
       " -0.538561525243386,\n",
       " 2.10935648218116,\n",
       " 2.03627605050869,\n",
       " 1.97391963943207,\n",
       " 1.09916887317774,\n",
       " 0.8005091922782891,\n",
       " 2.00600287000599,\n",
       " 1.30187835585944,\n",
       " 1.43655820246219,\n",
       " -4.20620028204653,\n",
       " 1.27167465289794,\n",
       " 0.0849610433434448,\n",
       " -1.26866090516724,\n",
       " 1.09731274477726,\n",
       " 1.89332209870375,\n",
       " 1.23354950742793,\n",
       " 1.80883446689686,\n",
       " 2.3056340718169,\n",
       " -1.80265202359478,\n",
       " 0.0282685625751696,\n",
       " -0.44773951863781297,\n",
       " 2.00431469276571,\n",
       " 0.103495185620932,\n",
       " -0.509364443797628,\n",
       " -2.34004742069023,\n",
       " 1.8765806523575903,\n",
       " 1.20531986555461,\n",
       " 0.994359168249249,\n",
       " 1.31357246377521,\n",
       " 2.20060200358192,\n",
       " -1.43781844899194,\n",
       " 1.98393480496937,\n",
       " 1.12374184651435,\n",
       " 0.0432220349070038,\n",
       " 1.90565862056748,\n",
       " -0.903758534179227,\n",
       " -2.05852272536359,\n",
       " 2.09903769058183,\n",
       " 1.1332656848803502,\n",
       " -0.7050608294429059,\n",
       " -1.82429505976067,\n",
       " -1.31103694456106,\n",
       " -1.64810153689623,\n",
       " -0.476018061053808,\n",
       " -1.60098770737501,\n",
       " 1.97924031653412,\n",
       " 1.910383985664,\n",
       " -0.621297519964678,\n",
       " -0.689841856285752,\n",
       " 1.24855128780091,\n",
       " 0.9447262555453628,\n",
       " -0.690879507069132,\n",
       " 1.6279870063087698,\n",
       " 1.27549271049083,\n",
       " 1.00907393571314,\n",
       " -0.489116617442488,\n",
       " -7.66413726846342,\n",
       " -2.36222831438949,\n",
       " 2.26796308388623,\n",
       " 1.85203126439249,\n",
       " 1.3055444898911002,\n",
       " 1.36290883205838,\n",
       " -0.286394330639728,\n",
       " -1.07088777887887,\n",
       " -1.53890919352421,\n",
       " -5.57713077394919,\n",
       " -0.0628988765851564,\n",
       " -0.0930966654812053,\n",
       " -0.0406869756561164,\n",
       " -0.231137544688164,\n",
       " -0.6945542180555351,\n",
       " -1.34799052317023,\n",
       " -1.19330633526041,\n",
       " 1.93971790656021,\n",
       " -1.8777889196852904,\n",
       " -1.79934785407132,\n",
       " 2.05147766686028,\n",
       " 1.93911601382885,\n",
       " -1.11532405959396,\n",
       " -0.39479759293411104,\n",
       " 1.92066928018816,\n",
       " -4.84437152213983,\n",
       " -0.499040154142197,\n",
       " -1.5345520768651,\n",
       " -0.232969640468684,\n",
       " -0.57738702559957,\n",
       " 2.06831075503637,\n",
       " -0.41389386050378496,\n",
       " -2.9215440526462,\n",
       " 1.2442845197201102,\n",
       " -1.5466979424878,\n",
       " -0.560106881805349,\n",
       " 1.2500164767060902,\n",
       " -1.20677530710026,\n",
       " -0.783047038881611,\n",
       " 1.19446059137564,\n",
       " 0.477268552218072,\n",
       " -1.35572903471868,\n",
       " -0.735635252494535,\n",
       " -1.2683250046419698,\n",
       " 2.12499510867588,\n",
       " -0.0867492612481421,\n",
       " -0.9730813699971308,\n",
       " 0.0552694627360427,\n",
       " 1.9789408411566105,\n",
       " 1.26675614071558,\n",
       " -0.510894395258824,\n",
       " 1.90505993950588,\n",
       " 2.33254308129418,\n",
       " 1.48745693761512,\n",
       " -0.4329206783876261,\n",
       " -22.177139245244604,\n",
       " 2.09357233983379,\n",
       " 1.18016642085748,\n",
       " 1.8215111689718704,\n",
       " -17.2022897690132,\n",
       " 0.498826881348483,\n",
       " -2.10688682768374,\n",
       " -0.39654942631093504,\n",
       " 0.236363588995954,\n",
       " 2.03218487568892,\n",
       " -1.12007310590293,\n",
       " 1.08897137341339,\n",
       " 1.0865871615845,\n",
       " -5.127841719257098,\n",
       " 0.23005706203534496,\n",
       " -0.5990533135642869,\n",
       " 0.6818814346009621,\n",
       " 1.8392586846689496,\n",
       " 2.00886195638853,\n",
       " -0.6711572396988629,\n",
       " 0.5288876535664601,\n",
       " 2.0958261608424498,\n",
       " 1.29785483551932,\n",
       " -1.09292839688228,\n",
       " -1.24907346357211,\n",
       " 1.7204618498916298,\n",
       " 1.23837108048984,\n",
       " 1.18935265862834,\n",
       " 1.24198629619878,\n",
       " 1.0063661978494,\n",
       " 1.96990530886792,\n",
       " 0.26555364024877104,\n",
       " -1.80682553483924,\n",
       " 1.49272915062942,\n",
       " -0.551410336839697,\n",
       " 0.816067045400895,\n",
       " -0.401849073537149,\n",
       " -0.19475708493593696,\n",
       " 1.19555978106408,\n",
       " -1.25447577889493,\n",
       " -2.57228724776808,\n",
       " -1.07104574964956,\n",
       " 2.05278634552751,\n",
       " 1.97981405254822,\n",
       " 1.31386688944795,\n",
       " 1.1267202356165,\n",
       " -0.766371495079755,\n",
       " -0.338809597732407,\n",
       " -22.85909871231169,\n",
       " -2.0389285039502,\n",
       " 0.0927266864981403,\n",
       " 1.05114196947656,\n",
       " 0.194569372868409,\n",
       " 0.372918193396077,\n",
       " -1.29330828023961,\n",
       " -1.93176822409463,\n",
       " 0.0620294684478967,\n",
       " 1.9360128003436696,\n",
       " -1.8934394189585,\n",
       " -0.340780810415802,\n",
       " -1.48985374809555,\n",
       " 1.98654246054662,\n",
       " 1.246696875528,\n",
       " 1.36157719785398,\n",
       " 2.07880970864479,\n",
       " 1.25760446557217,\n",
       " -0.4678664450819021,\n",
       " -2.56412704005522,\n",
       " 1.06493549193445,\n",
       " -1.5765228507200602,\n",
       " 1.8523467690397295,\n",
       " -1.04910744534697,\n",
       " -1.30575969795349,\n",
       " 0.874317181641101,\n",
       " 1.4976615014212298,\n",
       " 1.84798441134196,\n",
       " 2.04878283561817,\n",
       " 1.20297674035657,\n",
       " 1.10108600932052,\n",
       " 1.99826964537537,\n",
       " 1.32806778057084,\n",
       " -2.1731814831502603,\n",
       " -4.83972622332916,\n",
       " -0.0690412407542883,\n",
       " -2.6331486932903703,\n",
       " 0.530995842535085,\n",
       " -10.8973187405405,\n",
       " 2.02564393635495,\n",
       " -1.32547141186731,\n",
       " 1.1782444513126498,\n",
       " -0.89342838867946,\n",
       " 0.6269291618768879,\n",
       " 1.19444448462981,\n",
       " -13.8663860708351,\n",
       " 1.21798648885232,\n",
       " -0.299533121379456,\n",
       " 1.85224038029854,\n",
       " -0.8046591984862921,\n",
       " 1.12235075076526,\n",
       " -0.196800898898806,\n",
       " 1.83401657320956,\n",
       " -1.5275636260378,\n",
       " -1.54106082072289,\n",
       " -1.28202609699273,\n",
       " 0.305866051900275,\n",
       " -0.5701854811824449,\n",
       " -2.51665529564419,\n",
       " -2.1322499593130297,\n",
       " 1.2046988874554,\n",
       " 1.1843930225062802,\n",
       " -0.7217678411031621,\n",
       " -0.99737142720744,\n",
       " 2.05945416720564,\n",
       " -0.447056753147152,\n",
       " -0.40742827578715,\n",
       " 2.02011822826164,\n",
       " 1.42833224364704,\n",
       " -0.529886160767494,\n",
       " 1.5937255443064902,\n",
       " 1.4942159574544098,\n",
       " -4.48951688160866,\n",
       " -3.36828892411955,\n",
       " -0.8371499903974742,\n",
       " -1.28623825389744,\n",
       " 1.26284185284082,\n",
       " 1.1219366522423602,\n",
       " 0.9147302366349268,\n",
       " -1.00511017149701,\n",
       " -0.19940084273604006,\n",
       " -0.467813220418079,\n",
       " -0.166828153835319,\n",
       " 1.71766126880606,\n",
       " 0.688140550109522,\n",
       " 1.30068761861551,\n",
       " -0.886239460803782,\n",
       " 1.15916715509484,\n",
       " -0.0356483594253839,\n",
       " -0.8556570963098671,\n",
       " 0.0578163118200053,\n",
       " -0.694394379520398,\n",
       " 1.2880453085447,\n",
       " -0.481498843402646,\n",
       " -0.8797352257730771,\n",
       " 2.27726061753583,\n",
       " -0.613852960507109,\n",
       " 0.587664333695506,\n",
       " 1.85623684369587,\n",
       " -1.08022953361837,\n",
       " -1.21003086002605,\n",
       " 2.00823862561347,\n",
       " 2.0414294655051,\n",
       " 1.5790726994615,\n",
       " 1.30848713096117,\n",
       " -1.12090353415893,\n",
       " 0.652974227006353,\n",
       " -2.26407351783812,\n",
       " -0.4056620687851071,\n",
       " -1.83067897728388,\n",
       " -0.899586203422458,\n",
       " 1.9128232878707,\n",
       " -1.25789178370253,\n",
       " -1.45504928930497,\n",
       " -1.71956761117517,\n",
       " 1.25193407246688,\n",
       " 0.13844641646293,\n",
       " 0.032158337281064,\n",
       " -0.8415490186330301,\n",
       " -2.07288931221599,\n",
       " 1.12382345219309,\n",
       " 0.00949030000894213,\n",
       " 2.01283600641943,\n",
       " -4.91963852663139,\n",
       " 1.98494433803009,\n",
       " 1.26862201447476,\n",
       " 1.35030016679041,\n",
       " 2.0250279407333003,\n",
       " -1.5354276176346102,\n",
       " -0.636925314989727,\n",
       " 2.0977358558054,\n",
       " 1.9160555899125296,\n",
       " -0.25291248664252297,\n",
       " -0.467394018466609,\n",
       " 1.9324499033658895,\n",
       " -1.13825689912871,\n",
       " 0.264311779255946,\n",
       " 2.0623106072027,\n",
       " 1.13230764361388,\n",
       " -0.8568867085761659,\n",
       " 2.12772717186489,\n",
       " 2.12288884817826,\n",
       " -0.3797770591993371,\n",
       " -0.8408771422959009,\n",
       " 0.0790743163559475,\n",
       " 1.31125848597963,\n",
       " 0.33359025812181,\n",
       " 2.16602689762569,\n",
       " -1.56645599475695,\n",
       " -0.5176180483095411,\n",
       " 1.9974278477141,\n",
       " -0.38067879775520896,\n",
       " -0.851016121252217,\n",
       " 1.19377297163282,\n",
       " -1.00831979511053,\n",
       " -2.01660109794203,\n",
       " -0.0418975240154539,\n",
       " 0.809195836826062,\n",
       " -1.0141004498868,\n",
       " -11.3206331107815,\n",
       " 1.16172823090886,\n",
       " -0.11256084034303,\n",
       " -1.4510137222018,\n",
       " -1.20258294237016,\n",
       " -2.69923592092731,\n",
       " -0.41112895957430295,\n",
       " 2.18838414027573,\n",
       " 1.58358948695237,\n",
       " -1.51924353075082,\n",
       " 1.23776396940873,\n",
       " 2.22946404129627,\n",
       " 1.17947732833654,\n",
       " 1.95970877756142,\n",
       " 1.04559603979056,\n",
       " 2.04014081777102,\n",
       " 1.2276144135128602,\n",
       " -4.25414671158155,\n",
       " 1.9856622888966105,\n",
       " -0.817419256707841,\n",
       " -0.7374251519834109,\n",
       " -0.454749070621293,\n",
       " 1.98926088853427,\n",
       " 1.96813811058258,\n",
       " -1.08773030517065,\n",
       " -1.2805145237199398,\n",
       " 1.31835984022792,\n",
       " 0.0215416061740498,\n",
       " 2.01878998787211,\n",
       " 2.01102157311402,\n",
       " 1.06857259965962,\n",
       " 2.1880909078673,\n",
       " 1.24459930850356,\n",
       " 1.1008101822698502,\n",
       " -1.06776778820627,\n",
       " -0.466780250204834,\n",
       " 2.16131320800228,\n",
       " 1.31750275032105,\n",
       " -9.609682669539641,\n",
       " -1.1208258244108302,\n",
       " -2.58166771458129,\n",
       " -7.09432373119595,\n",
       " 0.0718535704578726,\n",
       " 1.81782025298949,\n",
       " -1.93208890797892,\n",
       " 2.17976252372702,\n",
       " -0.999667718853872,\n",
       " ...]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(df['V1'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>V1</th>\n",
       "      <th>V2</th>\n",
       "      <th>V3</th>\n",
       "      <th>V4</th>\n",
       "      <th>V5</th>\n",
       "      <th>V6</th>\n",
       "      <th>V7</th>\n",
       "      <th>V8</th>\n",
       "      <th>V9</th>\n",
       "      <th>V10</th>\n",
       "      <th>...</th>\n",
       "      <th>V21</th>\n",
       "      <th>V22</th>\n",
       "      <th>V23</th>\n",
       "      <th>V24</th>\n",
       "      <th>V25</th>\n",
       "      <th>V26</th>\n",
       "      <th>V27</th>\n",
       "      <th>V28</th>\n",
       "      <th>Amount</th>\n",
       "      <th>Class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.176563</td>\n",
       "      <td>0.323798</td>\n",
       "      <td>0.536927</td>\n",
       "      <td>1.047002</td>\n",
       "      <td>-0.368652</td>\n",
       "      <td>-0.728586</td>\n",
       "      <td>0.084678</td>\n",
       "      <td>-0.069246</td>\n",
       "      <td>-0.266389</td>\n",
       "      <td>0.155315</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.109627</td>\n",
       "      <td>-0.341365</td>\n",
       "      <td>0.057845</td>\n",
       "      <td>0.499180</td>\n",
       "      <td>0.415211</td>\n",
       "      <td>-0.581949</td>\n",
       "      <td>0.015472</td>\n",
       "      <td>0.018065</td>\n",
       "      <td>4.67</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.681109</td>\n",
       "      <td>-3.934776</td>\n",
       "      <td>-3.801827</td>\n",
       "      <td>-1.147468</td>\n",
       "      <td>-0.735540</td>\n",
       "      <td>-0.501097</td>\n",
       "      <td>1.038865</td>\n",
       "      <td>-0.626979</td>\n",
       "      <td>-2.274423</td>\n",
       "      <td>1.527782</td>\n",
       "      <td>...</td>\n",
       "      <td>0.652202</td>\n",
       "      <td>0.272684</td>\n",
       "      <td>-0.982151</td>\n",
       "      <td>0.165900</td>\n",
       "      <td>0.360251</td>\n",
       "      <td>0.195321</td>\n",
       "      <td>-0.256273</td>\n",
       "      <td>0.056501</td>\n",
       "      <td>912.00</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.140729</td>\n",
       "      <td>0.453484</td>\n",
       "      <td>0.247010</td>\n",
       "      <td>2.383132</td>\n",
       "      <td>0.343287</td>\n",
       "      <td>0.432804</td>\n",
       "      <td>0.093380</td>\n",
       "      <td>0.173310</td>\n",
       "      <td>-0.808999</td>\n",
       "      <td>0.775436</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.003802</td>\n",
       "      <td>0.058556</td>\n",
       "      <td>-0.121177</td>\n",
       "      <td>-0.304215</td>\n",
       "      <td>0.645893</td>\n",
       "      <td>0.122600</td>\n",
       "      <td>-0.012115</td>\n",
       "      <td>-0.005945</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-1.107073</td>\n",
       "      <td>-3.298902</td>\n",
       "      <td>-0.184092</td>\n",
       "      <td>-1.795744</td>\n",
       "      <td>2.137564</td>\n",
       "      <td>-1.684992</td>\n",
       "      <td>-2.015606</td>\n",
       "      <td>-0.007181</td>\n",
       "      <td>-0.165760</td>\n",
       "      <td>0.869659</td>\n",
       "      <td>...</td>\n",
       "      <td>0.130648</td>\n",
       "      <td>0.329445</td>\n",
       "      <td>0.927656</td>\n",
       "      <td>-0.049560</td>\n",
       "      <td>-1.892866</td>\n",
       "      <td>-0.575431</td>\n",
       "      <td>0.266573</td>\n",
       "      <td>0.414184</td>\n",
       "      <td>62.10</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-0.314818</td>\n",
       "      <td>0.866839</td>\n",
       "      <td>-0.124577</td>\n",
       "      <td>-0.627638</td>\n",
       "      <td>2.651762</td>\n",
       "      <td>3.428128</td>\n",
       "      <td>0.194637</td>\n",
       "      <td>0.670674</td>\n",
       "      <td>-0.442658</td>\n",
       "      <td>0.133499</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.312774</td>\n",
       "      <td>-0.799494</td>\n",
       "      <td>-0.064488</td>\n",
       "      <td>0.953062</td>\n",
       "      <td>-0.429550</td>\n",
       "      <td>0.158225</td>\n",
       "      <td>0.076943</td>\n",
       "      <td>-0.015051</td>\n",
       "      <td>2.67</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>-0.713266</td>\n",
       "      <td>0.869132</td>\n",
       "      <td>0.330114</td>\n",
       "      <td>0.902275</td>\n",
       "      <td>0.520836</td>\n",
       "      <td>-0.537036</td>\n",
       "      <td>0.301955</td>\n",
       "      <td>0.209117</td>\n",
       "      <td>-0.732441</td>\n",
       "      <td>-0.266402</td>\n",
       "      <td>...</td>\n",
       "      <td>0.114405</td>\n",
       "      <td>0.412489</td>\n",
       "      <td>0.223180</td>\n",
       "      <td>-0.430522</td>\n",
       "      <td>0.109774</td>\n",
       "      <td>-0.274569</td>\n",
       "      <td>-0.108067</td>\n",
       "      <td>-0.075318</td>\n",
       "      <td>4.95</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>1.219060</td>\n",
       "      <td>-0.207708</td>\n",
       "      <td>0.782809</td>\n",
       "      <td>0.271655</td>\n",
       "      <td>-0.456658</td>\n",
       "      <td>0.414201</td>\n",
       "      <td>-0.675133</td>\n",
       "      <td>0.057714</td>\n",
       "      <td>0.601970</td>\n",
       "      <td>-0.178378</td>\n",
       "      <td>...</td>\n",
       "      <td>0.170372</td>\n",
       "      <td>0.541010</td>\n",
       "      <td>-0.257175</td>\n",
       "      <td>-0.904534</td>\n",
       "      <td>0.414090</td>\n",
       "      <td>0.653565</td>\n",
       "      <td>0.014583</td>\n",
       "      <td>0.027320</td>\n",
       "      <td>47.65</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.683918</td>\n",
       "      <td>0.329216</td>\n",
       "      <td>-1.693025</td>\n",
       "      <td>-1.123644</td>\n",
       "      <td>2.662177</td>\n",
       "      <td>3.563731</td>\n",
       "      <td>-0.309291</td>\n",
       "      <td>-0.043369</td>\n",
       "      <td>0.050627</td>\n",
       "      <td>-0.361619</td>\n",
       "      <td>...</td>\n",
       "      <td>1.072188</td>\n",
       "      <td>0.671990</td>\n",
       "      <td>-0.208488</td>\n",
       "      <td>0.735029</td>\n",
       "      <td>0.633444</td>\n",
       "      <td>-0.281231</td>\n",
       "      <td>0.299686</td>\n",
       "      <td>0.293389</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>-1.127820</td>\n",
       "      <td>1.461342</td>\n",
       "      <td>0.526673</td>\n",
       "      <td>-0.158998</td>\n",
       "      <td>0.353158</td>\n",
       "      <td>-1.539196</td>\n",
       "      <td>0.727383</td>\n",
       "      <td>0.299275</td>\n",
       "      <td>-0.778768</td>\n",
       "      <td>-1.662588</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.068002</td>\n",
       "      <td>-0.494914</td>\n",
       "      <td>-0.343489</td>\n",
       "      <td>0.222014</td>\n",
       "      <td>0.541271</td>\n",
       "      <td>0.295158</td>\n",
       "      <td>-0.145161</td>\n",
       "      <td>-0.002592</td>\n",
       "      <td>0.76</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>-1.757794</td>\n",
       "      <td>0.821894</td>\n",
       "      <td>2.529482</td>\n",
       "      <td>-0.328198</td>\n",
       "      <td>-0.902062</td>\n",
       "      <td>0.739803</td>\n",
       "      <td>-0.119755</td>\n",
       "      <td>-0.797691</td>\n",
       "      <td>0.739508</td>\n",
       "      <td>3.458517</td>\n",
       "      <td>...</td>\n",
       "      <td>0.028491</td>\n",
       "      <td>0.778325</td>\n",
       "      <td>-0.073034</td>\n",
       "      <td>0.135780</td>\n",
       "      <td>-0.955393</td>\n",
       "      <td>-0.503613</td>\n",
       "      <td>-1.834281</td>\n",
       "      <td>-0.585528</td>\n",
       "      <td>10.00</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10 rows Ã— 30 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         V1        V2        V3        V4        V5        V6        V7  \\\n",
       "0  1.176563  0.323798  0.536927  1.047002 -0.368652 -0.728586  0.084678   \n",
       "1  0.681109 -3.934776 -3.801827 -1.147468 -0.735540 -0.501097  1.038865   \n",
       "2  1.140729  0.453484  0.247010  2.383132  0.343287  0.432804  0.093380   \n",
       "3 -1.107073 -3.298902 -0.184092 -1.795744  2.137564 -1.684992 -2.015606   \n",
       "4 -0.314818  0.866839 -0.124577 -0.627638  2.651762  3.428128  0.194637   \n",
       "5 -0.713266  0.869132  0.330114  0.902275  0.520836 -0.537036  0.301955   \n",
       "6  1.219060 -0.207708  0.782809  0.271655 -0.456658  0.414201 -0.675133   \n",
       "7  0.683918  0.329216 -1.693025 -1.123644  2.662177  3.563731 -0.309291   \n",
       "8 -1.127820  1.461342  0.526673 -0.158998  0.353158 -1.539196  0.727383   \n",
       "9 -1.757794  0.821894  2.529482 -0.328198 -0.902062  0.739803 -0.119755   \n",
       "\n",
       "         V8        V9       V10  ...       V21       V22       V23       V24  \\\n",
       "0 -0.069246 -0.266389  0.155315  ... -0.109627 -0.341365  0.057845  0.499180   \n",
       "1 -0.626979 -2.274423  1.527782  ...  0.652202  0.272684 -0.982151  0.165900   \n",
       "2  0.173310 -0.808999  0.775436  ... -0.003802  0.058556 -0.121177 -0.304215   \n",
       "3 -0.007181 -0.165760  0.869659  ...  0.130648  0.329445  0.927656 -0.049560   \n",
       "4  0.670674 -0.442658  0.133499  ... -0.312774 -0.799494 -0.064488  0.953062   \n",
       "5  0.209117 -0.732441 -0.266402  ...  0.114405  0.412489  0.223180 -0.430522   \n",
       "6  0.057714  0.601970 -0.178378  ...  0.170372  0.541010 -0.257175 -0.904534   \n",
       "7 -0.043369  0.050627 -0.361619  ...  1.072188  0.671990 -0.208488  0.735029   \n",
       "8  0.299275 -0.778768 -1.662588  ... -0.068002 -0.494914 -0.343489  0.222014   \n",
       "9 -0.797691  0.739508  3.458517  ...  0.028491  0.778325 -0.073034  0.135780   \n",
       "\n",
       "        V25       V26       V27       V28  Amount  Class  \n",
       "0  0.415211 -0.581949  0.015472  0.018065    4.67      0  \n",
       "1  0.360251  0.195321 -0.256273  0.056501  912.00      0  \n",
       "2  0.645893  0.122600 -0.012115 -0.005945    1.00      0  \n",
       "3 -1.892866 -0.575431  0.266573  0.414184   62.10      0  \n",
       "4 -0.429550  0.158225  0.076943 -0.015051    2.67      0  \n",
       "5  0.109774 -0.274569 -0.108067 -0.075318    4.95      0  \n",
       "6  0.414090  0.653565  0.014583  0.027320   47.65      0  \n",
       "7  0.633444 -0.281231  0.299686  0.293389    1.00      0  \n",
       "8  0.541271  0.295158 -0.145161 -0.002592    0.76      0  \n",
       "9 -0.955393 -0.503613 -1.834281 -0.585528   10.00      0  \n",
       "\n",
       "[10 rows x 30 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>V1</th>\n",
       "      <th>V2</th>\n",
       "      <th>V3</th>\n",
       "      <th>V4</th>\n",
       "      <th>V5</th>\n",
       "      <th>V6</th>\n",
       "      <th>V7</th>\n",
       "      <th>V8</th>\n",
       "      <th>V9</th>\n",
       "      <th>V10</th>\n",
       "      <th>...</th>\n",
       "      <th>V21</th>\n",
       "      <th>V22</th>\n",
       "      <th>V23</th>\n",
       "      <th>V24</th>\n",
       "      <th>V25</th>\n",
       "      <th>V26</th>\n",
       "      <th>V27</th>\n",
       "      <th>V28</th>\n",
       "      <th>Amount</th>\n",
       "      <th>Class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>21693.000000</td>\n",
       "      <td>21693.000000</td>\n",
       "      <td>21693.000000</td>\n",
       "      <td>21693.000000</td>\n",
       "      <td>21693.000000</td>\n",
       "      <td>21693.000000</td>\n",
       "      <td>21693.000000</td>\n",
       "      <td>21693.000000</td>\n",
       "      <td>21693.000000</td>\n",
       "      <td>21693.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>21693.000000</td>\n",
       "      <td>21693.000000</td>\n",
       "      <td>21693.000000</td>\n",
       "      <td>21693.000000</td>\n",
       "      <td>21693.000000</td>\n",
       "      <td>21693.000000</td>\n",
       "      <td>21693.000000</td>\n",
       "      <td>21693.000000</td>\n",
       "      <td>21693.000000</td>\n",
       "      <td>21693.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>-0.032403</td>\n",
       "      <td>0.047565</td>\n",
       "      <td>-0.091623</td>\n",
       "      <td>0.057805</td>\n",
       "      <td>-0.033983</td>\n",
       "      <td>-0.023207</td>\n",
       "      <td>-0.074203</td>\n",
       "      <td>0.002096</td>\n",
       "      <td>-0.044311</td>\n",
       "      <td>-0.091073</td>\n",
       "      <td>...</td>\n",
       "      <td>0.012471</td>\n",
       "      <td>0.003743</td>\n",
       "      <td>-0.001662</td>\n",
       "      <td>-0.002446</td>\n",
       "      <td>-0.000406</td>\n",
       "      <td>0.002367</td>\n",
       "      <td>0.001514</td>\n",
       "      <td>0.003203</td>\n",
       "      <td>86.776247</td>\n",
       "      <td>0.016411</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>2.106997</td>\n",
       "      <td>1.690911</td>\n",
       "      <td>1.870289</td>\n",
       "      <td>1.540329</td>\n",
       "      <td>1.530508</td>\n",
       "      <td>1.340599</td>\n",
       "      <td>1.596775</td>\n",
       "      <td>1.412650</td>\n",
       "      <td>1.158554</td>\n",
       "      <td>1.354886</td>\n",
       "      <td>...</td>\n",
       "      <td>0.850009</td>\n",
       "      <td>0.741348</td>\n",
       "      <td>0.629987</td>\n",
       "      <td>0.600144</td>\n",
       "      <td>0.520949</td>\n",
       "      <td>0.478279</td>\n",
       "      <td>0.424688</td>\n",
       "      <td>0.302048</td>\n",
       "      <td>235.644479</td>\n",
       "      <td>0.127052</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>-41.928738</td>\n",
       "      <td>-40.803981</td>\n",
       "      <td>-31.103685</td>\n",
       "      <td>-4.848504</td>\n",
       "      <td>-32.092129</td>\n",
       "      <td>-20.367836</td>\n",
       "      <td>-41.506796</td>\n",
       "      <td>-38.987263</td>\n",
       "      <td>-13.434066</td>\n",
       "      <td>-24.403185</td>\n",
       "      <td>...</td>\n",
       "      <td>-21.453736</td>\n",
       "      <td>-8.887017</td>\n",
       "      <td>-21.303666</td>\n",
       "      <td>-2.766638</td>\n",
       "      <td>-4.541819</td>\n",
       "      <td>-1.855355</td>\n",
       "      <td>-7.764147</td>\n",
       "      <td>-6.520075</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>-0.929371</td>\n",
       "      <td>-0.592921</td>\n",
       "      <td>-0.962975</td>\n",
       "      <td>-0.850069</td>\n",
       "      <td>-0.698296</td>\n",
       "      <td>-0.779041</td>\n",
       "      <td>-0.565297</td>\n",
       "      <td>-0.205943</td>\n",
       "      <td>-0.669752</td>\n",
       "      <td>-0.554596</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.225142</td>\n",
       "      <td>-0.538258</td>\n",
       "      <td>-0.162395</td>\n",
       "      <td>-0.356356</td>\n",
       "      <td>-0.317296</td>\n",
       "      <td>-0.326141</td>\n",
       "      <td>-0.069938</td>\n",
       "      <td>-0.053334</td>\n",
       "      <td>5.370000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>0.007545</td>\n",
       "      <td>0.075215</td>\n",
       "      <td>0.176534</td>\n",
       "      <td>-0.012868</td>\n",
       "      <td>-0.063948</td>\n",
       "      <td>-0.281565</td>\n",
       "      <td>0.030859</td>\n",
       "      <td>0.023159</td>\n",
       "      <td>-0.073996</td>\n",
       "      <td>-0.099291</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.024133</td>\n",
       "      <td>0.007273</td>\n",
       "      <td>-0.012327</td>\n",
       "      <td>0.036878</td>\n",
       "      <td>0.011561</td>\n",
       "      <td>-0.044870</td>\n",
       "      <td>0.002475</td>\n",
       "      <td>0.011765</td>\n",
       "      <td>21.950000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>1.315678</td>\n",
       "      <td>0.819749</td>\n",
       "      <td>1.020809</td>\n",
       "      <td>0.772388</td>\n",
       "      <td>0.615287</td>\n",
       "      <td>0.383633</td>\n",
       "      <td>0.563751</td>\n",
       "      <td>0.328411</td>\n",
       "      <td>0.590212</td>\n",
       "      <td>0.445474</td>\n",
       "      <td>...</td>\n",
       "      <td>0.192954</td>\n",
       "      <td>0.530333</td>\n",
       "      <td>0.146616</td>\n",
       "      <td>0.431931</td>\n",
       "      <td>0.354043</td>\n",
       "      <td>0.238629</td>\n",
       "      <td>0.095859</td>\n",
       "      <td>0.081749</td>\n",
       "      <td>76.480000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>2.451888</td>\n",
       "      <td>21.467203</td>\n",
       "      <td>4.069865</td>\n",
       "      <td>12.114672</td>\n",
       "      <td>29.162172</td>\n",
       "      <td>21.393069</td>\n",
       "      <td>34.303177</td>\n",
       "      <td>20.007208</td>\n",
       "      <td>9.125535</td>\n",
       "      <td>12.701539</td>\n",
       "      <td>...</td>\n",
       "      <td>27.202839</td>\n",
       "      <td>8.361985</td>\n",
       "      <td>15.626067</td>\n",
       "      <td>4.014444</td>\n",
       "      <td>5.541598</td>\n",
       "      <td>3.463246</td>\n",
       "      <td>9.879903</td>\n",
       "      <td>9.876371</td>\n",
       "      <td>7712.430000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8 rows Ã— 30 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                 V1            V2            V3            V4            V5  \\\n",
       "count  21693.000000  21693.000000  21693.000000  21693.000000  21693.000000   \n",
       "mean      -0.032403      0.047565     -0.091623      0.057805     -0.033983   \n",
       "std        2.106997      1.690911      1.870289      1.540329      1.530508   \n",
       "min      -41.928738    -40.803981    -31.103685     -4.848504    -32.092129   \n",
       "25%       -0.929371     -0.592921     -0.962975     -0.850069     -0.698296   \n",
       "50%        0.007545      0.075215      0.176534     -0.012868     -0.063948   \n",
       "75%        1.315678      0.819749      1.020809      0.772388      0.615287   \n",
       "max        2.451888     21.467203      4.069865     12.114672     29.162172   \n",
       "\n",
       "                 V6            V7            V8            V9           V10  \\\n",
       "count  21693.000000  21693.000000  21693.000000  21693.000000  21693.000000   \n",
       "mean      -0.023207     -0.074203      0.002096     -0.044311     -0.091073   \n",
       "std        1.340599      1.596775      1.412650      1.158554      1.354886   \n",
       "min      -20.367836    -41.506796    -38.987263    -13.434066    -24.403185   \n",
       "25%       -0.779041     -0.565297     -0.205943     -0.669752     -0.554596   \n",
       "50%       -0.281565      0.030859      0.023159     -0.073996     -0.099291   \n",
       "75%        0.383633      0.563751      0.328411      0.590212      0.445474   \n",
       "max       21.393069     34.303177     20.007208      9.125535     12.701539   \n",
       "\n",
       "       ...           V21           V22           V23           V24  \\\n",
       "count  ...  21693.000000  21693.000000  21693.000000  21693.000000   \n",
       "mean   ...      0.012471      0.003743     -0.001662     -0.002446   \n",
       "std    ...      0.850009      0.741348      0.629987      0.600144   \n",
       "min    ...    -21.453736     -8.887017    -21.303666     -2.766638   \n",
       "25%    ...     -0.225142     -0.538258     -0.162395     -0.356356   \n",
       "50%    ...     -0.024133      0.007273     -0.012327      0.036878   \n",
       "75%    ...      0.192954      0.530333      0.146616      0.431931   \n",
       "max    ...     27.202839      8.361985     15.626067      4.014444   \n",
       "\n",
       "                V25           V26           V27           V28        Amount  \\\n",
       "count  21693.000000  21693.000000  21693.000000  21693.000000  21693.000000   \n",
       "mean      -0.000406      0.002367      0.001514      0.003203     86.776247   \n",
       "std        0.520949      0.478279      0.424688      0.302048    235.644479   \n",
       "min       -4.541819     -1.855355     -7.764147     -6.520075      0.000000   \n",
       "25%       -0.317296     -0.326141     -0.069938     -0.053334      5.370000   \n",
       "50%        0.011561     -0.044870      0.002475      0.011765     21.950000   \n",
       "75%        0.354043      0.238629      0.095859      0.081749     76.480000   \n",
       "max        5.541598      3.463246      9.879903      9.876371   7712.430000   \n",
       "\n",
       "              Class  \n",
       "count  21693.000000  \n",
       "mean       0.016411  \n",
       "std        0.127052  \n",
       "min        0.000000  \n",
       "25%        0.000000  \n",
       "50%        0.000000  \n",
       "75%        0.000000  \n",
       "max        1.000000  \n",
       "\n",
       "[8 rows x 30 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Compute balance between fraud / not fraud records"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Percentage of fraud records: 1.641 %\n",
      "Percentage of legitimate records: 98.359 %\n"
     ]
    }
   ],
   "source": [
    "fraud_cnt = sum(df['Class'] == 1)\n",
    "not_fraud_cnt = sum(df['Class'] == 0)\n",
    "total_cnt = len(df)\n",
    "fraud_result = fraud_cnt /total_cnt * 100\n",
    "not_fraud_result = not_fraud_cnt /total_cnt * 100\n",
    "print(\"Percentage of fraud records: {:.3f} %\".format(fraud_result))\n",
    "print(\"Percentage of legitimate records: {:.3f} %\".format(not_fraud_result))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create training and test sets: X_train, X_test, y_train, y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training set percentage: 75.0%.\n",
      "Test set percentage: 25.0%.\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "df = pd.read_csv('fraud_data.csv')\n",
    "\n",
    "X = df.iloc[:,:-1]\n",
    "y = df.iloc[:,-1]\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=0)\n",
    "print(\"Training set percentage: {:.1f}%.\".format(100*len(X_train)/len(df)))\n",
    "print(\"Test set percentage: {:.1f}%.\".format(100*len(X_test)/len(df)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create and run dummy classifier\n",
    "\n",
    "Since the data set is unbalanced, having many more 'not fraud' entries than 'fraud' entries, we first create and run a dummy classifier to give us a baseline from which to evaluate our classifiers. Since the most frequent class is 'not fraud' (Class = 0), the dummy classifier always predicts 'not fraud'. Since precision computes the ratio of true positive predictions to all positive predictions and the dummy classifier makes no positive predictions, the dummy predictions are converted to 0.0 to prevent division by 0. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dummy accuracy =  0.9852507374631269\n",
      "Dummy recall =  0.0\n",
      "Dummy precision =  0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\seoha\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1437: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.dummy import DummyClassifier\n",
    "from sklearn.metrics import accuracy_score, recall_score, precision_score\n",
    "\n",
    "dummy_majority = DummyClassifier(strategy = 'most_frequent').fit(X_train, y_train)\n",
    "y_dummy_predictions = dummy_majority.predict(X_test)\n",
    "\n",
    "print(\"Dummy accuracy = \", accuracy_score(y_test, y_dummy_predictions))\n",
    "print(\"Dummy recall = \", recall_score(y_test, y_dummy_predictions))\n",
    "print(\"Dummy precision = \", precision_score(y_test, y_dummy_predictions))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create and run Support Vector classifier\n",
    "\n",
    "Create and run a support vector classifier using scikit-learn and default settings.  This is basically a baseline for subsequent support vector classifiers.\n",
    "\n",
    "Note that this classifier improves on all dummy metrics.  However, while the recall metric is probably the most important for this data, the recall result of 0.375 is far too low. Remember that recall is the ratio of true positive predictions to the sum of true positive and false negative predictions.  The recall metric measures the percentage of actual positive items in the test set that are identified as positive. We would like to identify as many fraud items as possible without creating too many false positives."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SVC accuracy =  0.9907817109144543\n",
      "SVC recall =  0.375\n",
      "SVC precision =  1.0\n"
     ]
    }
   ],
   "source": [
    "from sklearn.svm import SVC\n",
    "svc = SVC(gamma='auto').fit(X_train, y_train)\n",
    "svc_predicted = svc.predict(X_test)\n",
    "\n",
    "print(\"SVC accuracy = \", accuracy_score(y_test, svc_predicted))\n",
    "print(\"SVC recall = \", recall_score(y_test, svc_predicted))\n",
    "print(\"SVC precision = \", precision_score(y_test, svc_predicted))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dissect SciKit-Learn Confusion Matrix\n",
    "\n",
    "$\\begin{equation*}\n",
    "\\begin{vmatrix}\n",
    "TN & FP \\\\\n",
    "FN & TP \\\\\n",
    "\\end{vmatrix}\n",
    "\\end{equation*}$\n",
    "\n",
    "$\\begin{align}\n",
    "\\text{Where:}\n",
    "\\end{align}$\n",
    "\n",
    "$\\begin{equation*}\n",
    "TN = \\text{true negative} \\\\\n",
    "FP = \\text{false positive} \\\\\n",
    "FN = \\text{false negative} \\\\\n",
    "TP = \\text{true positive} \\\\\n",
    "\\end{equation*}$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " -----------\n",
      "| 5344|    0|\n",
      "|-----|-----|\n",
      "|   50|   30|\n",
      " -----------\n",
      "\n",
      "SVC accuracy =  0.9907817109144543\n",
      "SVC recall =  0.375\n",
      "SVC precision =  1.0\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "def print_confusion_matrix(confusion):\n",
    "    print(' -----------')\n",
    "    print('|{:5}|{:5}|'.format(confusion[0,0],confusion[0,1]))\n",
    "    print('|-----|-----|')\n",
    "    print('|{:5}|{:5}|'.format(confusion[1,0],confusion[1,1]))\n",
    "    print(' -----------')\n",
    "\n",
    "confusion = confusion_matrix(y_test, svc_predicted)\n",
    "tn = confusion[0,0]\n",
    "fp = confusion[0,1]\n",
    "fn = confusion[1,0]\n",
    "tp = confusion[1,1]\n",
    "svc_accuracy = (tn + tp) / (tn + fn + fp + tp)\n",
    "svc_recall = tp / (fn + tp)\n",
    "svc_precision = tp / (fp + tp)\n",
    "\n",
    "print_confusion_matrix(confusion)\n",
    "print()\n",
    "print(\"SVC accuracy = \", svc_accuracy)\n",
    "print(\"SVC recall = \", svc_recall)\n",
    "print(\"SVC precision = \", svc_precision)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Explicitly set the SVC hyperparameters to get a \"better\" support vector classifier.\n",
    "\n",
    "Using SVC classifier hyperparameters `{'C': 1e9, 'gamma': 1e-07}` suggested in the assignment instead of the defaults, create an SVC with higher accuracy, recall and precision."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " -----------\n",
      "| 5340|    4|\n",
      "|-----|-----|\n",
      "|   16|   64|\n",
      " -----------\n",
      "\n",
      "SVC accuracy =  0.9963126843657817\n",
      "SVC recall =  0.8\n",
      "SVC precision =  0.9411764705882353\n"
     ]
    }
   ],
   "source": [
    "svc = SVC(C=1e9, gamma=1e-07).fit(X_train, y_train)\n",
    "svc_predicted = svc.predict(X_test)\n",
    " \n",
    "print_confusion_matrix(confusion_matrix(y_test, svc_predicted))\n",
    "print()\n",
    "print(\"SVC accuracy = \", accuracy_score(y_test, svc_predicted))\n",
    "print(\"SVC recall = \", recall_score(y_test, svc_predicted))\n",
    "print(\"SVC precision = \", precision_score(y_test, svc_predicted))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create Optimal Support Vector classifier\n",
    "\n",
    "It is important to identify as many of the fraudulent transactions as possible. Therefore, in the absence of other constraints, we would like the recall metric (the number of true positives divided by the sum of true positives and false negatives) to be as high as possible. However, false positives are also an issue. False positives could mean significant inconvenience to honest customers through the denial of credit or unnecessary phone or email contact. To minimize false positives, we should maximize the precision metric.\n",
    "\n",
    "### Strategy:\n",
    "\n",
    "1) Conduct a (partial) grid search through the space of SVC hyperparameters using the recall scoring metric.\n",
    "\n",
    "2) Using the SVC model with the highest recall score, construct a precision-recall curve.\n",
    "\n",
    "3) Use the precision-recall curve and the model's decision function to find an acceptable trade-off between precision and recall."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 1: SVC Grid Search - Round 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best recall score: 0.8188405797101449\n",
      "Best C value: 10000000.0\n",
      "Best gamma value: 1e-07\n"
     ]
    }
   ],
   "source": [
    "# choose range of C values around 1e9 and gamma around 1e-07\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "svc = SVC()\n",
    "grid_values = {'gamma': [1e-05, 1e-06, 1e-07, 1e-08, 1e-09],\n",
    "               'C': [1e10, 1e9, 1e8, 1e7]}\n",
    "grid_svc = GridSearchCV(svc, param_grid = grid_values, scoring = 'recall', n_jobs=3, cv=3)\n",
    "grid_svc.fit(X_train, y_train)\n",
    "print(\"Best recall score:\", grid_svc.best_score_)\n",
    "print(\"Best C value:\", grid_svc.best_params_['C'])\n",
    "print(\"Best gamma value:\", grid_svc.best_params_['gamma'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 1: SVC Grid Search - Round 2\n",
    "\n",
    "#### NOTE: Further refinement of grid search results in no change. This is commented out because the support vector algorithm takes a long time."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`# choose narrower range of values around gamma=1e-07 and C=1e7\n",
    "svc2 = SVC()\n",
    "grid_values = {'gamma': [5e-07, 1e-07, 5e-08],\n",
    "               'C': [5e7, 1e7, 1e6, 5e5]}\n",
    "grid_svc2 = GridSearchCV(svc2, param_grid = grid_values, scoring = 'recall', n_jobs=3, cv=3)\n",
    "grid_svc2.fit(X_train, y_train)\n",
    "print(\"Best recall score:\", grid_svc2.best_score_)\n",
    "print(\"Best C value:\", grid_svc2.best_params_['C'])\n",
    "print(\"Best gamma value:\", grid_svc2.best_params_['gamma'])\n",
    " #\n",
    "Best recall score: 0.81884057971\n",
    "Best C value: 10000000.0\n",
    "Best gamma value: 1e-07`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 1: SVC Grid Search - Round 3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`# narrower range of values around gamma=1e-07 and C=1e7\n",
    "svc3 = SVC()\n",
    "grid_values = {'gamma': [0.8e-07, 0.9e-07, 1e-07, 1.1e-07, 1.2e-07],\n",
    "               'C': [3e7, 2e7, 1e7, 8e6, 4e6]}\n",
    "grid_svc3 = GridSearchCV(svc3, param_grid = grid_values, scoring = 'recall', n_jobs=3, cv=3)\n",
    "grid_svc3.fit(X_train, y_train)\n",
    "print(\"Best recall score:\", grid_svc3.best_score_)\n",
    "print(\"Best C value:\", grid_svc3.best_params_['C'])\n",
    "print(\"Best gamma value:\", grid_svc3.best_params_['gamma'])`\n",
    " #\n",
    "Best recall score: 0.81884057971\n",
    "Best C value: 10000000.0\n",
    "Best gamma value: 1e-07`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 1: SVC Grid Search - Round 4"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`# fix gamma at 1e-07 and try a narrow range around C=1e7\n",
    "svc4 = SVC()\n",
    "grid_values = {'gamma': [1e-07],\n",
    "               'C': [1.8e7, 1.6e7, 1.4e7, 1.2e7, 1e7,\n",
    "                     9.8e6, 9.6e6, 9.4e6, 9.2e6, 9e6,\n",
    "                     8.8e6, 8.6e6, 8.4e6, 8.2e6]}\n",
    "grid_svc4 = GridSearchCV(svc4, param_grid = grid_values, scoring = 'recall', n_jobs=3, cv=3)\n",
    "grid_svc4.fit(X_train, y_train)\n",
    "print(\"Best recall score:\", grid_svc4.best_score_)\n",
    "print(\"Best C value:\", grid_svc4.best_params_['C'])\n",
    "print(\"Best gamma value:\", grid_svc4.best_params_['gamma'])`\n",
    " #\n",
    "Best recall score: 0.81884057971\n",
    "Best C value: 10000000.0\n",
    "Best gamma value: 1e-07`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 2: Construct a Precision-Recall Curve from the best SVC Model\n",
    "\n",
    "The model (C=1e7, gamma=1e-07) gives SLIGHTLY better precision and accuracy than obtained from model using the suggested parameters from the course (C=1e9, gamma=1e-07)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Previous result (C=1e9, gamma=1e-07):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " -----------\n",
      "| 5340|    4|\n",
      "|-----|-----|\n",
      "|   16|   64|\n",
      " -----------\n",
      "\n",
      "SVC accuracy =  0.9963126843657817\n",
      "SVC recall =  0.8\n",
      "SVC precision =  0.9411764705882353\n"
     ]
    }
   ],
   "source": [
    "svc = SVC(C=1e9, gamma=1e-07).fit(X_train, y_train)\n",
    "svc_predicted = svc.predict(X_test)\n",
    " \n",
    "print_confusion_matrix(confusion_matrix(y_test, svc_predicted))\n",
    "print()\n",
    "print(\"SVC accuracy = \", accuracy_score(y_test, svc_predicted))\n",
    "print(\"SVC recall = \", recall_score(y_test, svc_predicted))\n",
    "print(\"SVC precision = \", precision_score(y_test, svc_predicted))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Somewhat better model (C=1e7, gamma=1e-07)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " -----------\n",
      "| 5341|    3|\n",
      "|-----|-----|\n",
      "|   18|   62|\n",
      " -----------\n",
      "\n",
      "SVC accuracy =  0.9961283185840708\n",
      "SVC recall =  0.775\n",
      "SVC precision =  0.9538461538461539\n"
     ]
    }
   ],
   "source": [
    "best_svc = SVC(C=1e7, gamma=1e-07, probability=True).fit(X_train, y_train)\n",
    "best_svc_predicted_all = best_svc.predict_proba(X_test)\n",
    "best_svc_predicted = best_svc_predicted_all[:,1]\n",
    "best_svc_predicted = best_svc_predicted > 0.5\n",
    " \n",
    "print_confusion_matrix(confusion_matrix(y_test, best_svc_predicted))\n",
    "print()\n",
    "print(\"SVC accuracy = \", accuracy_score(y_test, best_svc_predicted))\n",
    "print(\"SVC recall = \", recall_score(y_test, best_svc_predicted))\n",
    "print(\"SVC precision = \", precision_score(y_test, best_svc_predicted))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.05,\n",
       " 0.1,\n",
       " 0.15,\n",
       " 0.2,\n",
       " 0.25,\n",
       " 0.3,\n",
       " 0.35,\n",
       " 0.4,\n",
       " 0.45,\n",
       " 0.5,\n",
       " 0.55,\n",
       " 0.6,\n",
       " 0.65,\n",
       " 0.7,\n",
       " 0.75,\n",
       " 0.8,\n",
       " 0.85,\n",
       " 0.9,\n",
       " 0.95]"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[n/20 for n in list(range(1,20))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " -----------\n",
      "| 5324|   20|\n",
      "|-----|-----|\n",
      "|   14|   66|\n",
      " -----------\n",
      "\n",
      "Threshhold = 0.05\n",
      "SVC accuracy =  0.9937315634218289\n",
      "SVC recall =  0.825\n",
      "SVC precision =  0.7674418604651163\n",
      " -----------\n",
      "| 5333|   11|\n",
      "|-----|-----|\n",
      "|   16|   64|\n",
      " -----------\n",
      "\n",
      "Threshhold = 0.1\n",
      "SVC accuracy =  0.9950221238938053\n",
      "SVC recall =  0.8\n",
      "SVC precision =  0.8533333333333334\n",
      " -----------\n",
      "| 5338|    6|\n",
      "|-----|-----|\n",
      "|   16|   64|\n",
      " -----------\n",
      "\n",
      "Threshhold = 0.15\n",
      "SVC accuracy =  0.9959439528023599\n",
      "SVC recall =  0.8\n",
      "SVC precision =  0.9142857142857143\n",
      " -----------\n",
      "| 5340|    4|\n",
      "|-----|-----|\n",
      "|   16|   64|\n",
      " -----------\n",
      "\n",
      "Threshhold = 0.2\n",
      "SVC accuracy =  0.9963126843657817\n",
      "SVC recall =  0.8\n",
      "SVC precision =  0.9411764705882353\n",
      " -----------\n",
      "| 5340|    4|\n",
      "|-----|-----|\n",
      "|   16|   64|\n",
      " -----------\n",
      "\n",
      "Threshhold = 0.25\n",
      "SVC accuracy =  0.9963126843657817\n",
      "SVC recall =  0.8\n",
      "SVC precision =  0.9411764705882353\n",
      " -----------\n",
      "| 5341|    3|\n",
      "|-----|-----|\n",
      "|   16|   64|\n",
      " -----------\n",
      "\n",
      "Threshhold = 0.3\n",
      "SVC accuracy =  0.9964970501474927\n",
      "SVC recall =  0.8\n",
      "SVC precision =  0.9552238805970149\n",
      " -----------\n",
      "| 5341|    3|\n",
      "|-----|-----|\n",
      "|   16|   64|\n",
      " -----------\n",
      "\n",
      "Threshhold = 0.35\n",
      "SVC accuracy =  0.9964970501474927\n",
      "SVC recall =  0.8\n",
      "SVC precision =  0.9552238805970149\n",
      " -----------\n",
      "| 5341|    3|\n",
      "|-----|-----|\n",
      "|   17|   63|\n",
      " -----------\n",
      "\n",
      "Threshhold = 0.4\n",
      "SVC accuracy =  0.9963126843657817\n",
      "SVC recall =  0.7875\n",
      "SVC precision =  0.9545454545454546\n",
      " -----------\n",
      "| 5341|    3|\n",
      "|-----|-----|\n",
      "|   17|   63|\n",
      " -----------\n",
      "\n",
      "Threshhold = 0.45\n",
      "SVC accuracy =  0.9963126843657817\n",
      "SVC recall =  0.7875\n",
      "SVC precision =  0.9545454545454546\n",
      " -----------\n",
      "| 5341|    3|\n",
      "|-----|-----|\n",
      "|   18|   62|\n",
      " -----------\n",
      "\n",
      "Threshhold = 0.5\n",
      "SVC accuracy =  0.9961283185840708\n",
      "SVC recall =  0.775\n",
      "SVC precision =  0.9538461538461539\n",
      " -----------\n",
      "| 5341|    3|\n",
      "|-----|-----|\n",
      "|   18|   62|\n",
      " -----------\n",
      "\n",
      "Threshhold = 0.55\n",
      "SVC accuracy =  0.9961283185840708\n",
      "SVC recall =  0.775\n",
      "SVC precision =  0.9538461538461539\n",
      " -----------\n",
      "| 5341|    3|\n",
      "|-----|-----|\n",
      "|   19|   61|\n",
      " -----------\n",
      "\n",
      "Threshhold = 0.6\n",
      "SVC accuracy =  0.9959439528023599\n",
      "SVC recall =  0.7625\n",
      "SVC precision =  0.953125\n",
      " -----------\n",
      "| 5341|    3|\n",
      "|-----|-----|\n",
      "|   19|   61|\n",
      " -----------\n",
      "\n",
      "Threshhold = 0.65\n",
      "SVC accuracy =  0.9959439528023599\n",
      "SVC recall =  0.7625\n",
      "SVC precision =  0.953125\n",
      " -----------\n",
      "| 5342|    2|\n",
      "|-----|-----|\n",
      "|   19|   61|\n",
      " -----------\n",
      "\n",
      "Threshhold = 0.7\n",
      "SVC accuracy =  0.9961283185840708\n",
      "SVC recall =  0.7625\n",
      "SVC precision =  0.9682539682539683\n",
      " -----------\n",
      "| 5342|    2|\n",
      "|-----|-----|\n",
      "|   19|   61|\n",
      " -----------\n",
      "\n",
      "Threshhold = 0.75\n",
      "SVC accuracy =  0.9961283185840708\n",
      "SVC recall =  0.7625\n",
      "SVC precision =  0.9682539682539683\n",
      " -----------\n",
      "| 5342|    2|\n",
      "|-----|-----|\n",
      "|   21|   59|\n",
      " -----------\n",
      "\n",
      "Threshhold = 0.8\n",
      "SVC accuracy =  0.9957595870206489\n",
      "SVC recall =  0.7375\n",
      "SVC precision =  0.9672131147540983\n",
      " -----------\n",
      "| 5342|    2|\n",
      "|-----|-----|\n",
      "|   22|   58|\n",
      " -----------\n",
      "\n",
      "Threshhold = 0.85\n",
      "SVC accuracy =  0.995575221238938\n",
      "SVC recall =  0.725\n",
      "SVC precision =  0.9666666666666667\n",
      " -----------\n",
      "| 5342|    2|\n",
      "|-----|-----|\n",
      "|   22|   58|\n",
      " -----------\n",
      "\n",
      "Threshhold = 0.9\n",
      "SVC accuracy =  0.995575221238938\n",
      "SVC recall =  0.725\n",
      "SVC precision =  0.9666666666666667\n",
      " -----------\n",
      "| 5342|    2|\n",
      "|-----|-----|\n",
      "|   23|   57|\n",
      " -----------\n",
      "\n",
      "Threshhold = 0.95\n",
      "SVC accuracy =  0.9953908554572272\n",
      "SVC recall =  0.7125\n",
      "SVC precision =  0.9661016949152542\n"
     ]
    }
   ],
   "source": [
    "precisions = []\n",
    "recalls = []\n",
    "threshholds = []\n",
    "for threshhold in [n/20 for n in list(range(1,20))]:\n",
    "    best_svc_predicted = best_svc_predicted_all[:,1] > threshhold\n",
    "    precisions.append(precision_score(y_test, best_svc_predicted))\n",
    "    recalls.append(recall_score(y_test, best_svc_predicted))\n",
    "    threshholds.append(threshhold)\n",
    "\n",
    "    print_confusion_matrix(confusion_matrix(y_test, best_svc_predicted))\n",
    "    print()\n",
    "    print(\"Threshhold = {}\".format(threshhold))\n",
    "    print(\"SVC accuracy = \", accuracy_score(y_test, best_svc_predicted))\n",
    "    print(\"SVC recall = \", recall_score(y_test, best_svc_predicted))\n",
    "    print(\"SVC precision = \", precision_score(y_test, best_svc_predicted))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "ename": "IndexError",
     "evalue": "too many indices for array",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-59-511dd0be803b>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      9\u001b[0m     \u001b[0mplt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfigure\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     10\u001b[0m     \u001b[0mplt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mplot\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrecall\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mprecision\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcolor\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'black'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 11\u001b[1;33m     \u001b[0mplt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfill_between\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrecall\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mprecision\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0malpha\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0.1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcolor\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'blue'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     12\u001b[0m     \u001b[0mplt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mxlabel\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'Recall'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfontsize\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m16\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     13\u001b[0m     \u001b[0mplt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mylabel\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'Precision'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfontsize\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m16\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\matplotlib\\pyplot.py\u001b[0m in \u001b[0;36mfill_between\u001b[1;34m(x, y1, y2, where, interpolate, step, hold, data, **kwargs)\u001b[0m\n\u001b[0;32m   3052\u001b[0m         ret = ax.fill_between(x, y1, y2=y2, where=where,\n\u001b[0;32m   3053\u001b[0m                               \u001b[0minterpolate\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0minterpolate\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mstep\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mstep\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 3054\u001b[1;33m                               **kwargs)\n\u001b[0m\u001b[0;32m   3055\u001b[0m     \u001b[1;32mfinally\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3056\u001b[0m         \u001b[0max\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_hold\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mwashold\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\matplotlib\\__init__.py\u001b[0m in \u001b[0;36minner\u001b[1;34m(ax, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1853\u001b[0m                         \u001b[1;34m\"the Matplotlib list!)\"\u001b[0m \u001b[1;33m%\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mlabel_namer\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__name__\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1854\u001b[0m                         RuntimeWarning, stacklevel=2)\n\u001b[1;32m-> 1855\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0max\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1856\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1857\u001b[0m         inner.__doc__ = _add_data_doc(inner.__doc__,\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\matplotlib\\axes\\_axes.py\u001b[0m in \u001b[0;36mfill_between\u001b[1;34m(self, x, y1, y2, where, interpolate, step, **kwargs)\u001b[0m\n\u001b[0;32m   5095\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   5096\u001b[0m         \u001b[0mpolys\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 5097\u001b[1;33m         \u001b[1;32mfor\u001b[0m \u001b[0mind0\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mind1\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mcbook\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcontiguous_regions\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mwhere\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   5098\u001b[0m             \u001b[0mxslice\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mind0\u001b[0m\u001b[1;33m:\u001b[0m\u001b[0mind1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   5099\u001b[0m             \u001b[0my1slice\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0my1\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mind0\u001b[0m\u001b[1;33m:\u001b[0m\u001b[0mind1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\matplotlib\\cbook\\__init__.py\u001b[0m in \u001b[0;36mcontiguous_regions\u001b[1;34m(mask)\u001b[0m\n\u001b[0;32m   2009\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2010\u001b[0m     \u001b[1;31m# Find the indices of region changes, and correct offset\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2011\u001b[1;33m     \u001b[0midx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnonzero\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmask\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m!=\u001b[0m \u001b[0mmask\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2012\u001b[0m     \u001b[0midx\u001b[0m \u001b[1;33m+=\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2013\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mIndexError\u001b[0m: too many indices for array"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import precision_recall_curve\n",
    "\n",
    "#precision, recall, thresholds = precision_recall_curve(y_test, best_svc_predicted)\n",
    "\n",
    "for i in range(0, len(threshholds)):\n",
    "    recall = recalls[i]\n",
    "    precision = precisions[i]\n",
    "    plt.figure()\n",
    "    plt.plot(recall, precision, color='black')\n",
    "    plt.fill_between(recall, precision, alpha=0.1, color='blue')\n",
    "    plt.xlabel('Recall', fontsize=16)\n",
    "    plt.ylabel('Precision', fontsize=16)\n",
    "    plt.ylim([0.0, 1.01])\n",
    "    plt.xlim([0.0, 1.01])\n",
    "    plt.title('Precision-Recall Curve, Threshhold', fontsize=20)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note: investigate why this precision-recall curve is so simple."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 3: Choose Acceptable Trade-Off between Precision and Recall\n",
    "\n",
    "The optimal SVC C=1e7, gamma=1e-07) would catch about 80% of fraudulent cases and would misidentify 1 out of 20 non-fraud cases.  One can use a decision function for the classifier and vary the prediction threshold to \"adjust\" the balance between precision and recall. If we want our fraud detector to be more precise in transactions it flags and less annoying to customers we can raise the threshold to require greater confidence in our decisions.  Alternatively, if we want to be sure to capture most fraud occurences, we can lower the threshold.\n",
    "\n",
    "Using the training set and the decision function for the classifier with the best recall score, we vary the prediction threshold to create a listing of precision/recall trade-off values flagging \"good\" accuracy, recall and precision values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "threshold = -0.5\n",
      "SVC training recall =  0.8260869565217391\n",
      "SVC training precision =  0.957983193277311\n",
      "SVC training accuracy =  0.9964349376114082\n",
      "SVC test accuracy =  0.9963126843657817 *\n",
      "SVC test recall =  0.8 *\n",
      "SVC test precision =  0.9411764705882353 \n",
      "\n",
      "threshold = 0.0\n",
      "SVC training recall =  0.822463768115942\n",
      "SVC training precision =  0.9659574468085106\n",
      "SVC training accuracy =  0.996496404204315\n",
      "SVC test accuracy =  0.9964970501474927 *\n",
      "SVC test recall =  0.8 *\n",
      "SVC test precision =  0.9552238805970149 *\n",
      "\n",
      "threshold = 0.5\n",
      "SVC training recall =  0.8152173913043478\n",
      "SVC training precision =  0.9782608695652174\n",
      "SVC training accuracy =  0.9965578707972217\n",
      "SVC test accuracy =  0.9964970501474927 *\n",
      "SVC test recall =  0.8 *\n",
      "SVC test precision =  0.9552238805970149 *\n",
      "\n",
      "threshold = 1.0\n",
      "SVC training recall =  0.8115942028985508\n",
      "SVC training precision =  0.9824561403508771\n",
      "SVC training accuracy =  0.9965578707972217\n",
      "SVC test accuracy =  0.9963126843657817 *\n",
      "SVC test recall =  0.7875 *\n",
      "SVC test precision =  0.9545454545454546 *\n",
      "\n",
      "threshold = 1.5\n",
      "SVC training recall =  0.8079710144927537\n",
      "SVC training precision =  0.9867256637168141\n",
      "SVC training accuracy =  0.9965578707972217\n",
      "SVC test accuracy =  0.9961283185840708 *\n",
      "SVC test recall =  0.775 *\n",
      "SVC test precision =  0.9538461538461539 *\n",
      "\n",
      "threshold = 2.0\n",
      "SVC training recall =  0.8043478260869565\n",
      "SVC training precision =  0.9866666666666667\n",
      "SVC training accuracy =  0.996496404204315\n",
      "SVC test accuracy =  0.9959439528023599 *\n",
      "SVC test recall =  0.7625 *\n",
      "SVC test precision =  0.953125 *\n",
      "\n",
      "threshold = 2.5\n",
      "SVC training recall =  0.8007246376811594\n",
      "SVC training precision =  0.9910313901345291\n",
      "SVC training accuracy =  0.996496404204315\n",
      "SVC test accuracy =  0.9961283185840708 *\n",
      "SVC test recall =  0.7625 *\n",
      "SVC test precision =  0.9682539682539683 *\n",
      "\n",
      "threshold = 3.0\n",
      "SVC training recall =  0.7934782608695652\n",
      "SVC training precision =  0.9909502262443439\n",
      "SVC training accuracy =  0.9963734710185015\n",
      "SVC test accuracy =  0.9961283185840708 *\n",
      "SVC test recall =  0.7625 *\n",
      "SVC test precision =  0.9682539682539683 *\n",
      "\n",
      "threshold = 3.5\n",
      "SVC training recall =  0.7753623188405797\n",
      "SVC training precision =  0.9907407407407407\n",
      "SVC training accuracy =  0.9960661380539677\n",
      "SVC test accuracy =  0.995575221238938 *\n",
      "SVC test recall =  0.725 \n",
      "SVC test precision =  0.9666666666666667 *\n"
     ]
    }
   ],
   "source": [
    "# Use training set\n",
    "best_y_train_scores = best_svc.decision_function(X_train)\n",
    "best_y_test_scores = best_svc.decision_function(X_test)\n",
    "good_accuracy = 0.99\n",
    "good_recall = 0.75\n",
    "good_precision = 0.95\n",
    "\n",
    "for x in range(-1,8):\n",
    "    threshold = x/2.0 # values of threshold chosen by generate and test\n",
    "    print()\n",
    "    print(\"threshold =\", threshold)\n",
    "    # training data predictions\n",
    "    svc_train_predicted = [int(b) for b in best_y_train_scores >= threshold]\n",
    "    print(\"SVC training recall = \", recall_score(y_train, svc_train_predicted))\n",
    "    print(\"SVC training precision = \", precision_score(y_train, svc_train_predicted))\n",
    "    print(\"SVC training accuracy = \", accuracy_score(y_train, svc_train_predicted))\n",
    "\n",
    "    # test data predictions\n",
    "    svc_test_predicted = [int(b) for b in best_y_test_scores >= threshold]\n",
    "    \n",
    "    test_accuracy = accuracy_score(y_test, svc_test_predicted)\n",
    "    accuracy_flag = '*' if test_accuracy > good_accuracy else ''\n",
    "    print(\"SVC test accuracy = \", accuracy_score(y_test, svc_test_predicted), accuracy_flag)   \n",
    "    \n",
    "    test_recall = recall_score(y_test, svc_test_predicted)\n",
    "    recall_flag = '*' if test_recall > good_recall else ''\n",
    "    print(\"SVC test recall = \", recall_score(y_test, svc_test_predicted), recall_flag)\n",
    "    \n",
    "    test_precision = precision_score(y_test, svc_test_predicted)\n",
    "    precision_flag = '*' if test_precision > good_precision else ''\n",
    "    print(\"SVC test precision = \", precision_score(y_test, svc_test_predicted), precision_flag)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conclusions\n",
    "\n",
    "Depending on one's goals, use the above process to set an appropriate prediction threshold. It would probably be useful to try different types of classifiers on this problem such as logistic regression, Naive Bayes, neural networks etc.  One should also try some different SVC kernels.\n",
    "\n",
    "If one were to attempt to develop a classifier on the original Kaggle data set ([original Kaggle data set](https://www.kaggle.com/isaikumar/creditcardfraud), it is unlikely that support vector approaches would be realistic due to the much larger size of the data set, unless one had significant computing power available.  As mentioned, the 'Time' column in the original data set would probably require a time-series analysis. Since the original data set contains equal number of fraud and non-fraud cases, the accuracy measure would probably me more appropriate compared to the recall measure."
   ]
  }
 ],
 "metadata": {
  "coursera": {
   "course_slug": "python-machine-learning",
   "graded_item_id": "5yX9Z",
   "launcher_item_id": "eqnV3",
   "part_id": "Msnj0"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
